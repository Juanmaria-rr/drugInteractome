{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ####\n",
    "import findspark\n",
    "findspark.init(\"/opt/homebrew/Cellar/apache-spark/3.3.0/libexec\")\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "from psutil import virtual_memory\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "\n",
    "def detect_spark_memory_limit():\n",
    "    \"\"\"Spark does not automatically use all available memory on a machine. When working on large datasets, this may\n",
    "    cause Java heap space errors, even though there is plenty of RAM available. To fix this, we detect the total amount\n",
    "    of physical memory and allow Spark to use (almost) all of it.\"\"\"\n",
    "    mem_gib = virtual_memory().total >> 30\n",
    "    return int(mem_gib * 0.9)\n",
    "\n",
    "\n",
    "spark_mem_limit = detect_spark_memory_limit()\n",
    "spark_conf = (\n",
    "    SparkConf()\n",
    "    .set(\"spark.driver.memory\", f\"{spark_mem_limit}g\")\n",
    "    .set(\"spark.executor.memory\", f\"{spark_mem_limit}g\")\n",
    "    .set(\"spark.driver.maxResultSize\", \"0\")\n",
    "    .set(\"spark.debug.maxToStringFields\", \"2000000000\")\n",
    "    .set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"500000\")\n",
    "    ###.set(\"spark.executor.heartbeatInterval\", \"3600s\")\n",
    "    .set(\n",
    "        \"spark.sql.execution.arrow.pyspark.enabled\", \"true\"\n",
    "    )  ## esto lo pongo por esto: https://stackoverflow.com/questions/69973790/pyspark-spark-sparkexception-job-aborted-due-to-stage-failure-task-0-in-stage\n",
    "    .set(\"spark.ui.showConsoleProgress\", \"false\")\n",
    ")\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.config(conf=spark_conf)\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\")\n",
    "    .config(\"spark.driver.host\",\"localhost\") ### Run locally \n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "\n",
    "### Load datasets (target, interact db and molecule) with the last downloaded version (december 2022)\n",
    "interactors =\"/Users/juanr/Desktop/Target_Engine/data_download/december2022/interaction/\"\n",
    "interact_db = spark.read.parquet(interactors)\n",
    "                                 \n",
    "disease_path = \"/Users/juanr/Desktop/Target_Engine/data_download/december2022/diseases/\"\n",
    "diseases = spark.read.parquet(disease_path)\n",
    "\n",
    "target_path = \"/Users/juanr/Desktop/Target_Engine/data_download/december2022/targets/\"\n",
    "target = spark.read.parquet(target_path)\n",
    "\n",
    "molecule_path = \"/Users/juanr/Desktop/MR_Maya/Downloaded_20230110/molecule/\"\n",
    "molecule = spark.read.parquet(molecule_path)\n",
    "\n",
    "indication_path = \"/Users/juanr/Desktop/MR_Maya/Downloaded_20230110/indication/\"\n",
    "indication = spark.read.parquet(indication_path)\n",
    "\n",
    "indirecAssoc_path = \"/Users/juanr/Desktop/MR_Maya/Downloaded_20230110/associationByDatasourceIndirect/\"\n",
    "indirecAssoc = spark.read.parquet(indirecAssoc_path)\n",
    "\n",
    "## load symbols to complement EnsemblID\n",
    "symbol = target.select(\"id\", \"approvedSymbol\")\n",
    "\n",
    "## take diseases id with therapeutic areas\n",
    "diseases_name = diseases.select(\n",
    "    F.col(\"id\").alias(\"efoDisease\"),\n",
    "    F.col(\"name\").alias(\"diseaseName\"),\n",
    "    F.col(\"therapeuticAreas\"),\n",
    ")\n",
    "\n",
    "##### \n",
    "\n",
    "#### Load Direct Score data\n",
    "overallDirecAssocScore_path = \"/Users/juanr/Desktop/MR_Maya/Downloaded_20230110/assocOverallDirectJanuary2023/associationByOverallDirect\"\n",
    "overallDirecAssocScore = spark.read.parquet(overallDirecAssocScore_path)\n",
    "#### annotate Direct score\n",
    "oaDirectScore = overallDirecAssocScore.select(\n",
    "    F.col(\"targetId\").alias(\"targetIdoaDirect\"),\n",
    "    F.col(\"diseaseId\").alias(\"diseaseIdDirect\"),\n",
    "    F.col(\"score\").alias(\"scoreDirect\"),\n",
    ")\n",
    "\n",
    "#### Load Direct overall\n",
    "direcAssoc_path =\"/Users/juanr/Desktop/MR_Maya/Downloaded_20230110/associationByDatasourceDirect/\"\n",
    "direcAssoc = spark.read.parquet(direcAssoc_path)\n",
    "#### annotate which are the supporting datasourceId\n",
    "targetDirectAssoc = (\n",
    "    direcAssoc.groupBy(\"targetId\", \"diseaseId\")\n",
    "    .agg(F.collect_set(\"datasourceId\").alias(\"datasourceId\"))\n",
    "    .select(\n",
    "        F.col(\"targetId\").alias(\"targetIdDirect\"),\n",
    "        F.col(\"diseaseId\").alias(\"diseaseIdDirect\"),\n",
    "        F.col(\"datasourceId\").alias(\"datasourceIdDirect\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "##### Dataset format curation #####\n",
    "\n",
    "#### Read original dataset with all target-trait pairs per study\n",
    "path = \"/Users/juanr/Desktop/MR_Maya/MRdrug20230123_Analysis.tsv\"\n",
    "df2 = spark.read.csv(path, sep=r\"\\t\", header=True)\n",
    "\n",
    "## convert from string to array\n",
    "convert = [\n",
    "    \"adverse_effects\",\n",
    "    \"adverse_effects_studies\",\n",
    "    \"adverse_effects_bxy\",\n",
    "    \"mech\",\n",
    "    \"mech_studies\",\n",
    "    \"mech_coloc_h4\",\n",
    "    \"mech_bxy\",\n",
    "]\n",
    "## transform from multiple string to one\n",
    "transform = [\"adverse_effects_coloc_h4\", \"outcome_trait\"]\n",
    "\n",
    "df2 = df2.select(\n",
    "    *[F.split(col, \";\").alias(col) if col in convert else col for col in df2.columns]\n",
    ").select(\n",
    "    *[\n",
    "        F.concat(F.lit('\"'), som, F.lit('\"')).alias(som) if som in transform else som\n",
    "        for som in df2.columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = df2.select(\n",
    "    F.col(\"curated_ensid\").alias(\"ensid\"),\n",
    "    \"indice\",\n",
    "    \"mergedOutcomeTraitEfo2\",\n",
    "    \"protein_datasets\",\n",
    "    \"outcome_datasets\",\n",
    ")\n",
    "\n",
    "##### Join therapeutic areas #####\n",
    "\n",
    "### Build efo terms as array to explode later. \n",
    "### Select columns with therapeutic information coming from diseases_name\n",
    "\n",
    "prequeryset = (\n",
    "    df.withColumn(\"efo_array\", F.split(F.col(\"mergedOutcomeTraitEfo2\"), \", \"))\n",
    "    .withColumn(\"efo_ensid_individual_final\", F.explode_outer(F.col(\"efo_array\")))\n",
    "    .join(\n",
    "        diseases_name,\n",
    "        F.col(\"efoDisease\") == F.col(\"efo_ensid_individual_final\"),\n",
    "        \"left\",\n",
    "    )\n",
    "    .select(\n",
    "        \"ensid\",\n",
    "        \"mergedOutcomeTraitEfo2\",\n",
    "        \"indice\",\n",
    "        F.col(\"efo_ensid_individual_final\").alias(\"efo_ensid\"),\n",
    "        F.explode_outer(F.col(\"therapeuticAreas\")).alias(\"therapeuticAreas\"),\n",
    "        \"protein_datasets\",\n",
    "        \"outcome_datasets\",\n",
    "        \"efo_array\",\n",
    "    )\n",
    ")\n",
    "\n",
    "## Build a queryset with the therapeutic Areas to evaluate theses.\n",
    "queryset = prequeryset.groupBy(\n",
    "    \"ensid\", \"indice\", \"outcome_datasets\", \"protein_datasets\", \"efo_ensid\"\n",
    ").agg(\n",
    "    F.collect_set(\"therapeuticAreas\").alias(\"therapeuticAreas\"),\n",
    ")\n",
    "\n",
    "# take diseases with therapeutic areas to join with target B\n",
    "diseasesB = diseases.select(\n",
    "    F.col(\"id\").alias(\"id_B\"),\n",
    "    F.col(\"therapeuticAreas\").alias(\"therAreasB\"),\n",
    "    F.col(\"name\").alias(\"diseaseNameB\"),\n",
    ")\n",
    "\n",
    "# take diseases with therapeutic areas to join with target A\n",
    "diseasesA = diseases.select(\n",
    "    F.col(\"id\").alias(\"id_A\"),\n",
    "    F.col(\"therapeuticAreas\").alias(\"therAreasA\"),\n",
    "    F.col(\"name\").alias(\"diseaseNameA\"),\n",
    ")\n",
    "### get maxClinPhase for indication\n",
    "indicationsToJoin = indication.select(\n",
    "    \"id\", F.explode_outer(F.col(\"indications\")).alias(\"indications\")\n",
    ").select(\n",
    "    \"id\",\n",
    "    F.col(\"indications.disease\").alias(\"indicatedDisease\"),\n",
    "    F.col(\"indications.efoName\").alias(\"indicatedEfoName\"),\n",
    "    F.col(\"indications.maxPhaseForIndication\").alias(\"indicatedMaxPhaseIndication\"),\n",
    ")\n",
    "## obtaining chembl related to targets, therapeutic areas of diseases\n",
    "# from target-disease relation\n",
    "tar_group = (\n",
    "    molecule.select(\n",
    "        F.col(\"id\").alias(\"chemblIdTargetB\"),\n",
    "        F.col(\"name\").alias(\"drugNameTargetB\"),\n",
    "        F.col(\"maximumClinicalTrialPhase\").alias(\"maxClinTrialPhaseTargetB\"),\n",
    "        F.col(\"linkedDiseases\"),\n",
    "        F.explode_outer(\"linkedTargets.rows\").alias(\"chemblLinkedTargetB\"),\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"chemblIdTargetB\"),\n",
    "        F.col(\"drugNameTargetB\"),\n",
    "        F.col(\"maxClinTrialPhaseTargetB\"),\n",
    "        F.col(\"chemblLinkedTargetB\"),\n",
    "        F.explode_outer(\"linkedDiseases.rows\").alias(\"diseaseLinkedChemblTargetB\"),\n",
    "    )\n",
    "    .join(\n",
    "        indicationsToJoin,\n",
    "        (indicationsToJoin.id == F.col(\"chemblIdTargetB\"))\n",
    "        & (indicationsToJoin.indicatedDisease == F.col(\"diseaseLinkedChemblTargetB\")),\n",
    "        \"left\",\n",
    "    )\n",
    "    .join(diseasesB, F.col(\"diseaseLinkedChemblTargetB\") == diseasesB.id_B, \"left\")\n",
    "    .groupBy(\n",
    "        \"chemblLinkedTargetB\",\n",
    "        \"id_B\",\n",
    "        \"therAreasB\",\n",
    "        \"drugNameTargetB\",\n",
    "        F.col(\"indicatedDisease\").alias(\"indicatedDiseaseB\"),\n",
    "        \"maxClinTrialPhaseTargetB\",\n",
    "        F.col(\"indicatedMaxPhaseIndication\").alias(\"indicatedMaxPhaseIndicationB\"),\n",
    "    )\n",
    "    .agg(F.count(\"chemblLinkedTargetB\"))\n",
    ")\n",
    "### drugs for A. In theory is not required. \n",
    "tar_group2 = (\n",
    "    molecule.select(\n",
    "        F.col(\"id\").alias(\"chemblIdTargetA\"),\n",
    "        F.col(\"name\").alias(\"drugNameTargetA\"),\n",
    "        F.col(\"maximumClinicalTrialPhase\").alias(\"maxClinTrialPhaseTargetA\"),\n",
    "        F.col(\"linkedDiseases\"),\n",
    "        F.explode_outer(\"linkedTargets.rows\").alias(\"chemblLinkedTargetA\"),\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"chemblIdTargetA\"),\n",
    "        F.col(\"drugNameTargetA\"),\n",
    "        F.col(\"maxClinTrialPhaseTargetA\"),\n",
    "        F.col(\"chemblLinkedTargetA\"),\n",
    "        F.explode_outer(\"linkedDiseases.rows\").alias(\"diseaseLinkedChemblTargetA\"),\n",
    "    )\n",
    "    .join(\n",
    "        indicationsToJoin,\n",
    "        (indicationsToJoin.id == F.col(\"chemblIdTargetA\"))\n",
    "        & (indicationsToJoin.indicatedDisease == F.col(\"diseaseLinkedChemblTargetA\")),\n",
    "        \"left\",\n",
    "    )\n",
    "    .join(diseasesA, F.col(\"diseaseLinkedChemblTargetA\") == diseasesA.id_A, \"left\")\n",
    "    .groupBy(\n",
    "        \"chemblLinkedTargetA\",\n",
    "        \"id_A\",\n",
    "        \"therAreasA\",\n",
    "        \"drugNameTargetA\",\n",
    "        F.col(\"indicatedDisease\").alias(\"indicatedDiseaseA\"),\n",
    "        \"maxClinTrialPhaseTargetA\",\n",
    "        F.col(\"indicatedMaxPhaseIndication\").alias(\"indicatedMaxPhaseIndicationA\"),\n",
    "    )\n",
    "    .agg(F.count(\"chemblLinkedTargetA\"))\n",
    ")\n",
    "\n",
    "### Get interactors using IntAct database\n",
    "# filter by 0.42 score & add linked CHEMBL (tar_group) of the partners\n",
    "\n",
    "look_other = (\n",
    "    interact_db.filter(F.col(\"sourceDatabase\") == \"intact\")\n",
    "    .select(\"sourceDatabase\", \"targetA\", \"targetB\", \"scoring\")\n",
    "    .filter(F.col(\"scoring\") > \"0.42\")\n",
    "    .join(queryset, queryset.ensid == F.col(\"targetA\"), \"right\")\n",
    "    .join(tar_group, F.col(\"targetB\") == tar_group.chemblLinkedTargetB, \"left\")\n",
    "    .join(tar_group2, F.col(\"targetA\") == tar_group2.chemblLinkedTargetA, \"left\") ### remove\n",
    "    .withColumn(\"therAreasDiseases\", F.explode_outer(F.col(\"therapeuticAreas\")))\n",
    "    .withColumn(\"therAreasTargetA\", F.explode_outer(F.col(\"therAreasA\"))) ### remove\n",
    "    .withColumn(\"therAreasTargetB\", F.explode_outer(F.col(\"therAreasB\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_step = (\n",
    "    look_other.join(symbol, F.col(\"targetB\") == symbol.id, \"left\")\n",
    "    ###  Assess if the efo term is similar: \n",
    "    .withColumn(\"sameEfoensid_A\",\n",
    "        F.when( \n",
    "            (F.col(\"id_A\").isNotNull()) &\n",
    "            (F.col(\"efo_ensid\")==F.col(\"id_A\")), \n",
    "            F.lit('sameDisease'))\n",
    "        .when(\n",
    "            (F.col(\"id_A\").isNotNull()) &\n",
    "            (F.col(\"efo_ensid\")!=F.col(\"id_A\")), F.lit('difDisease'))\n",
    "        .otherwise(F.lit('noDisease')))\n",
    "    \n",
    "    .withColumn(\"sameEfoensid_B\",\n",
    "        F.when( \n",
    "            (F.col(\"id_B\").isNotNull()) &\n",
    "            (F.col(\"efo_ensid\")==F.col(\"id_B\")), \n",
    "            F.lit('sameDisease'))\n",
    "        .when(\n",
    "            (F.col(\"id_B\").isNotNull()) &\n",
    "            (F.col(\"efo_ensid\")!=F.col(\"id_B\")), F.lit('difDisease'))\n",
    "        .otherwise(F.lit('noDisease')))\n",
    "    ## Assess if therapeuticAreas are the same\n",
    "    .withColumn(\n",
    "        \"coincident_A_string\",\n",
    "        F.when(\n",
    "            F.col(\"therAreasTargetA\").isNull(), F.lit('noTherAreaTargetA'))\n",
    "        .when (\n",
    "            (\n",
    "                (F.col(\"therAreasTargetA\").isNotNull()) &\n",
    "                (F.col('therAreasDiseases')== F.col(\"therAreasTargetA\")) \n",
    "            ), \n",
    "            F.lit(\"coincident\"))\n",
    "        .when ( \n",
    "            F.col(\"therAreasDiseases\") != F.col(\"therAreasTargetA\"),\n",
    "            F.lit(\"nonCoincident\"),\n",
    "        )\n",
    "        .otherwise(F.lit(\"dif\")),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"coincident_B_string\",\n",
    "        F.when(\n",
    "            F.col(\"therAreasTargetB\").isNull(), F.lit('noTherAreaTargetB'))\n",
    "        .when (\n",
    "            (   \n",
    "                (F.col(\"therAreasTargetB\").isNotNull()) &\n",
    "                (F.col('therAreasDiseases')== F.col(\"therAreasTargetB\"))   \n",
    "            ), \n",
    "            F.lit(\"coincident\"))\n",
    "        .when ( \n",
    "            F.col(\"therAreasDiseases\") != F.col(\"therAreasTargetB\"),\n",
    "            F.lit(\"nonCoincident\"),\n",
    "        )\n",
    "        .otherwise(F.lit(\"dif\")),\n",
    "    )\n",
    "    ## Write drug from A if therapy areas are the same as disease\n",
    "    .withColumn(\n",
    "        \"drugFromA_string\",\n",
    "        F.when(\n",
    "            F.col(\"coincident_A_string\") == \"coincident\",\n",
    "            F.concat_ws(\n",
    "                \"_\", F.col(\"drugNameTargetA\"), F.col(\"indicatedMaxPhaseIndicationA\")\n",
    "            ),\n",
    "        ).otherwise(  ##F.col('therAreasA')))\n",
    "            F.lit(None)\n",
    "        ),\n",
    "    )\n",
    "    ## Write drug from B if therapy areas are in the same as disease\n",
    "    .withColumn(\n",
    "        \"drugFromB_string\",\n",
    "        F.when(\n",
    "            (F.col('targetB').isNotNull()) &\n",
    "            (F.col('ensid') != F.col('targetB')) &\n",
    "            (F.col(\"coincident_B_string\") == \"coincident\"),\n",
    "            F.concat_ws(\n",
    "                \"_\",\n",
    "                F.col(\"approvedSymbol\"),\n",
    "                F.col(\"drugNameTargetB\"),\n",
    "                F.col(\"indicatedMaxPhaseIndicationB\"),\n",
    "            ),\n",
    "        ).otherwise(  ##F.col('therAreasB')))\n",
    "            F.lit(None)\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"drugFromA_repurposing_string\",\n",
    "        F.when(\n",
    "            (F.col(\"coincident_A_string\") == \"nonCoincident\")\n",
    "            & (F.col(\"drugNameTargetA\").isNotNull()),\n",
    "            F.concat_ws(\n",
    "                \"_\", F.col(\"drugNameTargetA\"), F.col(\"indicatedMaxPhaseIndicationA\")\n",
    "            ),\n",
    "        ).otherwise(  ##F.col('therAreasTargetA')))\n",
    "            F.lit(None)\n",
    "        ),\n",
    "    )\n",
    "        .withColumn(\n",
    "        \"drugFromBNovel_string\",\n",
    "        F.when(\n",
    "            (F.col('targetB').isNotNull()) &\n",
    "            (F.col('ensid') != F.col('targetB')) &\n",
    "            (F.col(\"coincident_B_string\") == \"nonCoincident\") &\n",
    "            (F.col(\"therAreasB\").isNotNull()),\n",
    "            F.concat_ws(\n",
    "                \"_\",\n",
    "                F.col(\"approvedSymbol\"),\n",
    "                F.col(\"drugNameTargetB\"),\n",
    "                F.col(\"indicatedMaxPhaseIndicationB\"),\n",
    "            ),\n",
    "        ).otherwise(  ##F.col('therAreasTargetB')))\n",
    "            F.lit(None)\n",
    "        ),\n",
    "    )\n",
    "    ## Write drug from A if efo_disease is the same as disease\n",
    "    .withColumn(\n",
    "        \"drugFromA_efo\",\n",
    "        F.when(\n",
    "            F.col(\"sameEfoensid_A\") == \"sameDisease\",\n",
    "            F.concat_ws(\n",
    "                \"_\", F.col(\"drugNameTargetA\"), F.col(\"indicatedMaxPhaseIndicationA\"),F.col(\"id_A\"))\n",
    "            )\n",
    "        .otherwise(F.lit(None)))\n",
    "        \n",
    "    ## Write drug from B if efo_disease is the same as disease\n",
    "    .withColumn(\n",
    "        \"drugFromB_efo\",\n",
    "        F.when(\n",
    "            (F.col('targetB').isNotNull()) &\n",
    "            (F.col('ensid') != F.col('targetB')) & \n",
    "            (F.col(\"sameEfoensid_B\") == \"sameDisease\"),\n",
    "            F.concat_ws(\n",
    "                \"_\",F.col(\"approvedSymbol\"), F.col(\"drugNameTargetB\"), F.col(\"indicatedMaxPhaseIndicationA\"),F.col(\"id_B\"))\n",
    "            )\n",
    "        .otherwise(F.lit(None)))\n",
    "\n",
    "    .withColumn(\n",
    "        \"coincident_A\",\n",
    "        F.array_intersect(F.col(\"therAreasA\"), F.col(\"therapeuticAreas\")),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"coincident_B\",\n",
    "        F.array_intersect(F.col(\"therAreasB\"), F.col(\"therapeuticAreas\")),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"nonCoincidentA\", F.array_except(F.col(\"therapeuticAreas\"), F.col(\"therAreasA\"))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"nonCoincidentB\", F.array_except(F.col(\"therapeuticAreas\"), F.col(\"therAreasB\"))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_step=(first_step\n",
    ".groupBy(\n",
    "    F.col(\"ensid\").alias(\"ensid2\"),\n",
    "    F.col(\"indice\").alias(\"indice2\"))\n",
    ".agg(\n",
    "\n",
    "    F.collect_set(F.col(\"drugFromA_efo\")).alias(\"drugFromA_trait\"),        \n",
    "    F.collect_set(F.col(\"drugFromB_efo\")).alias(\"drugFromB_trait\"),\n",
    "    F.collect_set(F.col(\"drugFromA_string\")).alias(\"drugFromA_therArea\"),\n",
    "    F.collect_set(F.col(\"drugFromA_repurposing_string\")).alias(\"drugFromA_repurposing_string\"),\n",
    "    F.collect_set(F.col(\"drugFromB_string\")).alias(\"drugFromB_therArea\"),\n",
    "    F.collect_set(F.col(\"drugFromBNovel_string\")).alias(\"drugFromBNovel_string\"))\n",
    ".withColumn(\n",
    "    \"drugFromARepurposing_therArea\",\n",
    "    F.array_except(\"drugFromA_repurposing_string\", \"drugFromA_therArea\"),\n",
    ")\n",
    ".withColumn(\n",
    "    \"drugFromBNovel_therArea\",\n",
    "    F.array_except(\"drugFromBNovel_string\", \"drugFromB_therArea\"),\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support=(queryset\n",
    "    .join(\n",
    "        targetDirectAssoc,\n",
    "        (targetDirectAssoc.targetIdDirect == F.col(\"ensid\"))\n",
    "        & (targetDirectAssoc.diseaseIdDirect == F.col(\"efo_ensid\"))\n",
    "        ,\n",
    "        \"left\")\n",
    "    .join(\n",
    "        oaDirectScore, \n",
    "        (F.col(\"ensid\")==oaDirectScore.targetIdoaDirect) &\n",
    "        (F.col(\"efo_ensid\")==oaDirectScore.diseaseIdDirect)\n",
    "        ,\n",
    "        \"left\")  \n",
    "    .withColumn('datasourceIdDirect_take',\n",
    "        F.explode(F.col('datasourceIdDirect')))\n",
    "    .groupBy(\n",
    "    F.col(\"ensid\").alias(\"ensid3\"),\n",
    "    F.col(\"indice\"))\n",
    "    .agg(\n",
    "        F.collect_set(F.col('datasourceIdDirect_take')).alias('datasourceIdDirect'),\n",
    "        F.collect_set(F.col('scoreDirect')).alias('scoreDirect'),\n",
    "    )\n",
    "    ).repartition(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_step=(second_step\n",
    ".join(support, \n",
    "(support.ensid3==F.col('ensid2')) &\n",
    "(support.indice==F.col('indice2')),'left')\n",
    ".withColumnRenamed(\"indice\",'indiceJoin')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_step = (df2.join(\n",
    "    third_step,\n",
    "    (df2.indice == third_step.indiceJoin),\n",
    "    \"left\"\n",
    "))\n",
    "\n",
    "fourth_step=fourth_step.drop(\n",
    "    \"ensid3\",\n",
    "    \"ensid2\",\n",
    "    'indice2',\n",
    "    'indiceJoin',\n",
    "    \"protein_datasets2\",\n",
    "    \"protein_datasets3\",\n",
    "    \"outcome_datasets2\",\n",
    "    \"outcome_datasets3\",\n",
    "    \"drugFromA_repurposing_string\",\n",
    "    \"drugFromBNovel_string\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
